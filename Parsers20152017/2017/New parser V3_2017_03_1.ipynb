{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc14bf8",
   "metadata": {},
   "source": [
    "### Вторая версия парсера, изменения - сохранение объемов работ и добавление обработки xlsx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7793bf",
   "metadata": {},
   "source": [
    "Также высылаю расширенную версию json. Так как выяснили, что физ. объёмы полей, связанных с завершённостью работы по проекту в целом и в месяц, а также остатков по проекту, всё-таки важны и не всегда они пересчитываются из процентов. Теперь такие поля как complite_state, current_remain, whole_remain и mounth_complite имеют две вариации - в процентах и в физ. объёме. Заполняем по факту наличия в данных, если есть оба - заполняем оба варианта, если нет - заполняем что есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c09d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from xlrd import xldate_as_datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import win32com.client as win32\n",
    "import pyexcel as p\n",
    "import json\n",
    "import traceback\n",
    "import openpyxl\n",
    "import msoffcrypto\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04618011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Не вывожу ошибки\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Меняем директорию для удобства обработки\n",
    "os.chdir(r\"C:\\Users\\Илья\\Desktop\\Work\\ГПН КИП-2\\My parsers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd45032",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции и переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = {'Январь':1,\n",
    "     'Февраль':2,\n",
    "     'Март':3,\n",
    "     'Апрель':4,\n",
    "     'Май':5,\n",
    "     'Июнь':6,\n",
    "     'Июль':7,\n",
    "     'Август':8,\n",
    "     'Сентябрь':9,\n",
    "     'Октябрь':10,\n",
    "     'Ноябрь':11, \n",
    "     'Декабрь':12}\n",
    "\n",
    "M_={numb:name for name,numb in M.items()}\n",
    "\n",
    "words_type_table={(\"наименование работ\",\"план\"):\"work\",\n",
    "                  (\"наименование и марка\",):(\"equipment\",\"None\"),\n",
    "                  (\"наименование должност\",):(\"human\",\"None\"),\n",
    "                  (\"наименование субподрядн\",\"наименование должност\"):(\"human\",\"subcontracting\"),\n",
    "                  (\"наименование субподрядн\",\"наименование и марка\"):(\"equipment\",\"subcontracting\")\n",
    "                 }\n",
    "\n",
    "is_not_None=lambda v:v not in [None,\"\",str(None),\"nan\",float(\"nan\")]\n",
    "  \n",
    "def val_is_None(row_values,num_val):\n",
    "    if len(row_values)>num_val:\n",
    "        is_None=row_values[num_val] in [None,\"\",str(None)]\n",
    "    else:\n",
    "        is_None=True\n",
    "    return is_None\n",
    "\n",
    "\n",
    "def check_type_table(cols):\n",
    "    line_cols=\" \".join(cols).lower()\n",
    "#     print(line_cols)\n",
    "    \n",
    "    for words in words_type_table:\n",
    "        if all([(w in line_cols) for w in list(words)]):\n",
    "#             print(f\"Тип определен как {words_type_table[words]}\")\n",
    "            return words_type_table[words]\n",
    "#     print(f\"Тип определен как None\")\n",
    "    \n",
    "\n",
    "def create_cols(sh,start_table_rx,last_head_rx,type_file):\n",
    "    if type_file==\"xls\":\n",
    "        names=list(zip(*[[str(cell.value) for cell in sh.row(rx)] for rx in range(start_table_rx,last_head_rx+1)]))\n",
    "    if type_file==\"xlsx\":\n",
    "        names=list(zip(*[[str(cell.value) for cell in sh[rx]] for rx in range(start_table_rx,last_head_rx+1)]))\n",
    "    \n",
    "    name_to_line=lambda list_names:\" \".join([n for n in list_names if n!=str(None)])\n",
    "    return list(map(name_to_line,names))\n",
    "\n",
    "#Органичения - если в индексе буквы индексом считатся не будет\n",
    "def val_is_index(val):\n",
    "    return ((re.search(r\"^[0-9]+.[0-9]+\",str(val).strip(\".\").strip())!=None)|(str(val).isdigit()))&(\"resource\" not in str(val))\n",
    "\n",
    "# 'work id': '2001-02-03 00:00:00' заплатка для обработки\n",
    "def work_id_to_format(work_id):\n",
    "    if re.search(r\"[0-9]{4}-[0-9]{2}-[0-9]{2}\",str(work_id))!=None:\n",
    "        parts_id=re.findall(r\"[0-9]{4}-[0-9]{2}-[0-9]{2}\",str(work_id))[0].split(\"-\")\n",
    "        print(parts_id)\n",
    "        return f\"{parts_id[2].lstrip('0')}.{parts_id[1].lstrip('0')}.{parts_id[0][-1]}\"\n",
    "    return work_id\n",
    "\n",
    "#Запуск заплатки для обработки \n",
    "def ind_preprocess(ind):\n",
    "    ind=work_id_to_format(ind)\n",
    "    ind=re.sub(r\"[^0-9.]\",\"\",str(ind).replace(\".0\",\"\")).strip(\".\")\n",
    "    if len(ind)>20:\n",
    "        ind=str(ind)[:20]\n",
    "    return ind\n",
    "\n",
    "#Сокращаем индекс с конца чтобы добавить все высокоуровневые работы, которые указаны, частью которых является эта работа\n",
    "def get_high_level_works(hierar_i,high_level_works):\n",
    "    hl_works=[]\n",
    "    while len(hierar_i)>=1: #Для len(hierar_i)==1 не может быть работ высшего уровня\n",
    "        hierar_i=\".\".join(hierar_i.split(\".\")[:-1])\n",
    "        if hierar_i in high_level_works:\n",
    "            hl_works.append(f\"{hierar_i} {high_level_works[hierar_i]}\")\n",
    "    return hl_works\n",
    "\n",
    "def all_vals_int(vals): #,rx_is_first #Модель удалит строку если в ней будут значения 1,2,3,4 например\n",
    "    if \"Примечание\" in vals:\n",
    "        vals.remove(\"Примечание\")\n",
    "    try:\n",
    "        if all([str(v).replace(\".0\",\"\") in list(map(str,list(range(25)))) for v in vals]): #Все значения инт, проверяем\n",
    "            int_vals=[int(str(v).replace(\".0\",\"\")) for v in vals]\n",
    "            if len(int_vals)>=3: #Не понятно как выбирать это число\n",
    "                if sorted(int_vals)==int_vals: #Проверяем что числа идут по неубыванию:\n",
    "                    differences=[v2-v1 for v1,v2 in list(zip(int_vals,int_vals[1:]))] #Разница между соседними числами должна быть 1 (0 нельзя,нужные строки попадут)\n",
    "                    if all(list(map(lambda d:d==1,differences))): \n",
    "                        print(f\"Нашлась строка числовых столбцов {int_vals}\")\n",
    "                        return True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_index(last_indexes,row_values):\n",
    "    val=row_values[0]\n",
    "    row_values_not_none=[str(v) for v in row_values]\n",
    "    val_not_none=row_values_not_none[0]\n",
    "    \n",
    "    if val_is_index(val):\n",
    "        if len(row_values_not_none)==2:\n",
    "            type_index=\"high_level\"\n",
    "        else:\n",
    "            type_index=\"low_level\"\n",
    "        return ind_preprocess(val),type_index\n",
    "    \n",
    "    if len(row_values)>1: \n",
    "        if val_is_index(row_values[1]): \n",
    "            if len(row_values_not_none)==2: #Если индекс во второй строке и всего 2 значения - работа высокоуровневая\n",
    "                type_index=\"high_level\"\n",
    "            else:\n",
    "                type_index=\"low_level\"\n",
    "            return ind_preprocess(row_values[1]),type_index\n",
    "    \n",
    "\n",
    "#     print(f\"Значение {val} не распознается как индекc\")\n",
    "    #В случае отсутствия индекса в первых двух значениях считаем что его нет и генерируем из предидущего \n",
    "    if len(last_indexes)==0:\n",
    "        return (\"1\",\"high_level\")\n",
    "    else:\n",
    "        last_index,type_index=last_indexes[-1]\n",
    "        if type_index==\"high_level\":\n",
    "            return (ind_preprocess(last_index)+\".1\",\"low_level\") #если верхнеуровневый - добавляем .1, \n",
    "        \n",
    "        if type_index==\"low_level\":\n",
    "            last_number=str(last_index).split(\".\")[-1]\n",
    "            previous_part=str(last_index).split(\".\")[:-1]\n",
    "            \n",
    "            new_index=previous_part+[str(int(last_number)+1)] #Если низкоуровневый - добавляем 1 к последнему числу\n",
    "            new_index=\".\".join(new_index)\n",
    "            return (ind_preprocess(new_index),\"low_level\")\n",
    "            \n",
    "            \n",
    "#Для файлов СМГ 03 НГСК в высокоуровневых работах в конце строки появляется слово \"план\" убираем \n",
    "def del_words_end_line(value_list):\n",
    "    row_values_not_none=[str(v) for v in value_list if (v!=\"\")&(v!=None)]\n",
    "    if len(row_values_not_none)>0:\n",
    "        if (val_is_index(value_list[0])|val_is_index(value_list[1]))&(len(row_values_not_none)==3): #3 - индекс, значение, план\n",
    "            if \"план\" in value_list:\n",
    "                value_list[value_list.index(\"план\")]=\"\"\n",
    "\n",
    "    return value_list\n",
    "\n",
    "#Нужные признаки для json кроме work title и work id\n",
    "needed_vals_for_json=[\n",
    "'measurements',\n",
    " 'amount',\n",
    " 'start_date_plan',\n",
    " 'start_date_estimate',\n",
    " 'start_date_fact',\n",
    " 'stop_date_plan',\n",
    " 'stop_date_estimate',\n",
    " 'stop_date_fact',\n",
    " 'complite_state_plan',\n",
    " 'complite_state_fact',\n",
    " 'whole_remain_value',\n",
    " 'current_complete_perc',\n",
    " 'mounth_complite_plan',\n",
    " 'mounth_complite_fact',\n",
    "] #'comments'\n",
    "    \n",
    "def have_values_for_json(row,new_name_cols):\n",
    "    have_values=False\n",
    "    row_values=[cell.value for cell in row]\n",
    "    #Проверяем заполненно ли хоть одно значение из нужных для json\n",
    "    if any([(val not in [None,\"\",str(None)]) for col,val in zip(new_name_cols,row_values) if col in needed_vals_for_json]):\n",
    "        have_values=True\n",
    "    return have_values\n",
    "\n",
    "def row_include_work(row,prev_row,next_row,new_name_cols):\n",
    "    include_work=False\n",
    "    row_values=[cell.value for cell in row]\n",
    "#     print(\"Проверяем включает ли работы строка\",row_values)\n",
    "    \n",
    "    #Если в строке есть слово план, следующая строка существует (не None) и есть слово факт\n",
    "    if next_row!=None:\n",
    "        next_row_values=[cell.value for cell in next_row]\n",
    "        if (\"план\" in row_values)&(\"факт\" in next_row_values):\n",
    "            include_work=True\n",
    "\n",
    "\n",
    "    #Если в строке есть слово факт, предидушщая строка существует (не None) и в ней есть слово план\n",
    "    if prev_row!=None:\n",
    "        prev_row_values=[cell.value for cell in prev_row]\n",
    "        if (\"факт\" in row_values)&(\"план\" in prev_row_values):\n",
    "            include_work=True\n",
    "    \n",
    "    #Функция проверяет строку на наличие работы вне зависимости от наличия слов \"план\" и \"факт\"\n",
    "    #Если у строки есть индекс и второе непустое значение + заполнено хоть 1 значение из нужных для json\n",
    "    #И следующая строка равна по длинее этой, и не содержит индекса в первых трех значениях\n",
    "    #Считаем что это пара строк план-факт\n",
    "    def find_work_row_without_plan_fact(first_row,second_row,new_name_cols):\n",
    "        include_work=False\n",
    "        first_row_values=[cell.value for cell in first_row]\n",
    "        second_row_values=[cell.value for cell in second_row]\n",
    "\n",
    "        if (len(first_row_values)>=3) & (len(second_row_values)>=3) & (len(new_name_cols)>=3):\n",
    "            first_row_have_index=val_is_index(first_row_values[0])|val_is_index(first_row_values[1]) #Проверяем наличие индекса в первых двух значениях\n",
    "            second_row_empty_three_first_values=val_is_None(second_row_values,1)&val_is_None(second_row_values,2)&val_is_None(second_row_values,3)\n",
    "            \n",
    "            if first_row_have_index&second_row_empty_three_first_values&have_values_for_json(first_row,new_name_cols):\n",
    "                include_work=True\n",
    "        return include_work\n",
    "            \n",
    "    if next_row!=None:\n",
    "        if find_work_row_without_plan_fact(first_row=row,second_row=next_row,new_name_cols=new_name_cols):\n",
    "            include_work=True\n",
    "        \n",
    "    if prev_row!=None:\n",
    "        if find_work_row_without_plan_fact(first_row=prev_row,second_row=row,new_name_cols=new_name_cols):\n",
    "            include_work=True\n",
    "        \n",
    "    return include_work\n",
    "\n",
    "#Проверяем стоит ли сохранять информацию из строки\n",
    "def is_valide(row,prev_row,next_row,type_table,new_name_cols):\n",
    "    needed_row=False\n",
    "    row_values=[cell.value for cell in row]\n",
    "    row_values_not_none=[str(v) for v in row_values if (v!=\"\")&(v!=None)]\n",
    "    \n",
    "    first_val=row_values[0]\n",
    "    if first_val not in [\"\",None]: #\n",
    "        needed_row=True\n",
    "    else: \n",
    "\n",
    "        #Если второе значение индекс, строку тоже обрабатываем\n",
    "        if (len(row_values_not_none)>0)&(len(row_values)>1):\n",
    "            if val_is_index(str(row_values[1])): #|(\"gpn\" in row_values_not_none[0])\n",
    "                needed_row=True\n",
    "        \n",
    "        #Если строка включает данные о работах - берем ее\n",
    "        if row_include_work(row,prev_row,next_row,new_name_cols):\n",
    "            needed_row=True\n",
    "        \n",
    "        #Для ресурсов обрабатываем все строки\n",
    "        if type_table!=\"work\":\n",
    "            needed_row=True\n",
    "    \n",
    "    #Если первые 3 значения цифры 1,2,3 или 2,3,4 - строка числовая, пропускать ее нельзя\n",
    "    try:\n",
    "        three_vals=list(map(int,row_values[:3]))\n",
    "        if three_vals==[1,2,3]:\n",
    "            needed_row=False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        three_vals=list(map(int,row_values[1:4]))\n",
    "        if three_vals==[2,3,4]:\n",
    "            needed_row=False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return needed_row\n",
    "\n",
    "#Достаем предидущую и следующую строку\n",
    "def get_next_prev_rows(rx,end_table_rx,last_head_rx):\n",
    "    prev_row,next_row=None,None\n",
    "    if rx!=(last_head_rx+1):\n",
    "        if type_file==\"xls\":\n",
    "            prev_row=sh.row(rx-1)\n",
    "            \n",
    "        if type_file==\"xlsx\":\n",
    "            prev_row=sh[rx-1]\n",
    "    \n",
    "    if rx!=end_table_rx: #Проверяем что значение не последнее\n",
    "        if type_file==\"xls\":\n",
    "            next_row=sh.row(rx+1)\n",
    "        \n",
    "        if type_file==\"xlsx\":\n",
    "            next_row=sh[rx+1]\n",
    "    return prev_row,next_row\n",
    "\n",
    "#Вытаскиваем последний высокоуровневый индекс и привязываем к нему ресурс\n",
    "def get_last_high_ind(last_indexes):\n",
    "    last_high_indexes=[i for i in last_indexes if i[1]==\"high_level\"]\n",
    "    if len(last_high_indexes)==0:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return last_high_indexes[-1][0]\n",
    "\n",
    "\n",
    "def create_vals(sh,last_head_rx,end_table_rx,type_file,type_table,new_name_cols):\n",
    "    high_level_works={}\n",
    "    all_row_vals=[]\n",
    "    last_indexes=[]\n",
    "    \n",
    "    for rx in range(last_head_rx+1,end_table_rx+1):\n",
    "        \n",
    "        if type_file==\"xls\":\n",
    "            row=sh.row(rx)\n",
    "            \n",
    "        if type_file==\"xlsx\":\n",
    "            row=sh[rx]\n",
    "        \n",
    "        #Достали следующую и предидущую строки\n",
    "        prev_row,next_row=get_next_prev_rows(rx,end_table_rx,last_head_rx)\n",
    "#         print(\"row_values_1\",[cell.value for cell in row])\n",
    "        if is_valide(row,prev_row,next_row,type_table,new_name_cols): #Отсеиваем строки с пустым первым значением + без объемов работ\n",
    "            row_values=[cell.value for cell in row] #Значения не в строчном виде для сохранения и дальнейшего извлечения дат \n",
    "            row_values=del_words_end_line(row_values) #Заплатка - удаляем слов план из конца высокоуровневой строки чтобы ловилась \n",
    "            row_values_not_none=[str(v) for v in row_values if (v!=\"\")&(v!=None)]\n",
    "            row_line=\" \".join(row_values_not_none)\n",
    "            \n",
    "            \n",
    "            #тестирую убрал (not all_vals_int(row_values_not_none)) вообще\n",
    "            if (type_table==\"work\"): #,rx_is_first решил ослабить условие\n",
    "                \n",
    "                #Если индекс пустой - считаем что это ресурс и генерируем для него индекс\n",
    "                if row_values[0] in [\"\",None]: #!\n",
    "                    #ЗАКОМЕНЧЕНО - считаем что все строки с пустыми индексами это ресурсы\n",
    "                    #Вытаскиваем индекс строки (если его нет - генерируем) и его тип (низкоуровневый или высокоуровневый)\n",
    "#                     new_index,type_index=get_index(last_indexes,row_values)\n",
    "                    \n",
    "                    #Вытаскиваем последний высокий индекс\n",
    "                    last_high_i=get_last_high_ind(last_indexes)\n",
    "                    row_values[0]=f\"{last_high_i}_resource\" #Заполняем первое значение, индекс - привязка к работе+resource\n",
    "                \n",
    "                    #Обновляем строки с учетом обновления первого значения\n",
    "                    row_values_not_none=[str(v) for v in row_values if (v!=\"\")&(v!=None)]\n",
    "                    row_line=\" \".join(row_values_not_none)\n",
    "                \n",
    "                \n",
    "#                 print(\"row_values_2\",row_values,len(row_values))\n",
    "                \n",
    "                #! убрано &(len(row_values_not_none)==2) для теста\n",
    "                print(\"rule 1\",val_is_index(row_values[0])&((not val_is_None(row_values,1))|(not val_is_None(row_values,2)))&(not row_include_work(row,prev_row,next_row,new_name_cols))) # &((not val_is_None(row_values,1))|(not val_is_None(row_values,2)))\n",
    "                if val_is_index(row_values[0])&((not val_is_None(row_values,1))|(not val_is_None(row_values,2)))&(not row_include_work(row,prev_row,next_row,new_name_cols)): #2 значения + второе не пустое - индекс считаем высокоуровневым\n",
    "                    print(1)\n",
    "                    high_level_works[ind_preprocess(row_values_not_none[0])]=row_values_not_none[1]\n",
    "                    last_indexes.append((ind_preprocess(row_values_not_none[0]),\"high_level\"))\n",
    "                    \n",
    "                    \n",
    "                #Если индекс на втором месте, третья не пустая, и длинна 2 - считаем высокоуровневой работой\n",
    "                #! убрано &(len(row_values_not_none)==2) для теста\n",
    "                elif (val_is_index(row_values[1]))&((not val_is_None(row_values,2))|(not val_is_None(row_values,3)))&(not row_include_work(row,prev_row,next_row,new_name_cols)): #!  \n",
    "                    high_level_works[ind_preprocess(row_values[1])]=row_values[2]\n",
    "                    last_indexes.append((ind_preprocess(row_values[1]),\"high_level\"))\n",
    "                \n",
    "                #!Если индекс определен и есть работы в строке - прибавляем высокоуровневые работы\n",
    "                elif (val_is_index(row_values[0]))&(row_include_work(row,prev_row,next_row,new_name_cols)):  #Только если индекс на первом месте добавляем работы высокого уровня\n",
    "                    \n",
    "                    #Вытаскиваем все работы высшего уровня к которым относится работа в строке\n",
    "                    hl_works=get_high_level_works(ind_preprocess(row_values[0]),high_level_works)\n",
    "                    #Добавляем к строке все работы высшего уровня\n",
    "                    row_values+=hl_works\n",
    "                    all_row_vals.append(row_values)\n",
    "                    last_indexes.append((ind_preprocess(row_values[0]),\"low_level\"))\n",
    "                \n",
    "                \n",
    "# Закоменчено, так как следующие условие тоже добавляет строки ресурсов                \n",
    "#                 elif row_values[0]==\"resource\":\n",
    "#                     all_row_vals.append(row_values)\n",
    "                    \n",
    "                elif row_include_work(row,prev_row,next_row,new_name_cols): #Если есть работы в строке, но первое значение не индекс (для факта)\n",
    "                    all_row_vals.append(row_values)\n",
    "                else:\n",
    "#                     print(f\"Строка не сохранена {row_values}\")\n",
    "                    pass\n",
    "                \n",
    "            else: #Добавляем значения для ресурсов\n",
    "                if not all_vals_int(row_values_not_none):\n",
    "                    all_row_vals.append(row_values)\n",
    "    print(\"all_row_vals\",all_row_vals)            \n",
    "    print(\"high_level_works\",high_level_works)\n",
    "    return all_row_vals #!Неравная длинна, возможно не равна длинне колонок\n",
    "\n",
    "\n",
    "for_rename_cols={\n",
    "   ( \"наименование работ\",):\"work title\",\n",
    "    (\"п/п\",):'work id',\n",
    "    (\"ед.\",\"изм\"):\"measurements\",\n",
    "    (\"всего\",):\"amount\", #\"кол-во\",\n",
    "    (\"начал\",'работ',\"план\"):\"start_date_plan\",\n",
    "    (\"начал\",'работ',\"ожид\"):\"start_date_estimate\",\n",
    "    (\"начал\",'работ',\"факт\"):\"start_date_fact\",\n",
    "    (\"оконч\",\"план\"):\"stop_date_plan\",\n",
    "    (\"оконч\",\"ожид\"):\"stop_date_estimate\",\n",
    "    (\"оконч\",\"факт\"):\"stop_date_fact\",\n",
    "    (\"выполн\",\"нач\",\"план\"):\"complite_state_plan\",\n",
    "    (\"выполн\",\"нач\",\"факт\"):\"complite_state_fact\",\n",
    "    (\"остат\",):\"whole_remain_value\",\n",
    "#     (\"общий\",\"%\"):,\n",
    "    (\"%\",\"выполн\",\"меся\"):\"current_complete_perc\", #,\n",
    "    (\"месяц\",\"план\"):\"mounth_complite_plan\",\n",
    "    (\"задан\",\"факт\"):\"mounth_complite_fact\",\n",
    "#     (\"%\",\"выполн\",\"план\"):\"mounth_complite_fact\",\n",
    "#     (\"задан\",\"план\"):'mounth_complite_plan', #+,\"месяц\"\n",
    "#     (\"задан\",\"факт\"):'mounth_complite_fact', #+,\"месяц\"\n",
    "    tuple([m.lower() for m in list(M)]):1,\n",
    "    (\"примечан\",):\"comments\"\n",
    "}\n",
    "\n",
    "\n",
    "#Функция для приведения названия колонок к красивому виду, добавляет фразу которая должна быть в колонке\n",
    "def get_needed_phrase(col,markers_cols):\n",
    "    markers_in_col=[w for w in markers_cols if w in str(col).lower()]\n",
    "    if (len(markers_in_col)>0)&(all([\n",
    "        (col not in markers_cols) for col in [col,col.strip().strip(\"\\n\"),col.strip().strip(\"\\n\").lower()]])):\n",
    "        marker=markers_in_col[0]\n",
    "        return str(col).lower().replace(marker,\"\").strip().replace(\"\\n\",\" \")\n",
    "\n",
    "#1. После слов план и файт не должно быть ничего, чистим все что после\n",
    "def clear_plan_fact(line):\n",
    "    if re.search(r\".*факт|.*план\",str(line).lower())!=None:\n",
    "#         line=re.findall(r\".*факт|.*план\",str(line).lower())[0]\n",
    "        line=str(line).lower().replace(\"на дату\",\"\").strip() #мешает\n",
    "        line=re.sub(r\" +\",' ',line)\n",
    "        line=line.replace(\"ожид/\",\"\").replace(\"ожид/\",\"\").strip() #удаляем /факт для столбца ожид/факт \n",
    "    return line\n",
    "\n",
    "def rename_cols(table,type_table,for_rename_cols=for_rename_cols):\n",
    "    \n",
    "    \n",
    "#     print(f\"Старые названия колонок {table.columns.to_list()}\")\n",
    "    if type_table==\"work\":\n",
    "        #Чищу колонки план и факт от окончаний\n",
    "        table.columns=[clear_plan_fact(c) for c in table.columns]\n",
    "        print(table.columns)\n",
    "        \n",
    "        #Переименовываю колонки c план, факт и ожид к нужному виду\n",
    "        markers_cols=[\"план\",\"ожид\",\"факт\"]\n",
    "        is_marker_in_col=lambda col:any([w in str(col).lower() for w in markers_cols])\n",
    "        get_markers_in_col=lambda col:[w for w in markers_cols if w in str(col).lower()]\n",
    "\n",
    "        phrase_for_append=None\n",
    "        new_columns=[]\n",
    "        for col in table.columns:\n",
    "            if is_marker_in_col(col):\n",
    "                if (get_needed_phrase(col,markers_cols) is not None):\n",
    "                    phrase_for_append=get_needed_phrase(col,markers_cols)\n",
    "                #Как для строки с фразой для добавления так и для обычной строки добавляем имя единнообразно\n",
    "                new_columns.append(phrase_for_append+\" \"+str(get_markers_in_col(col)[0]))\n",
    "            else:\n",
    "                new_columns.append(col.replace(\"\\n\",\" \"))\n",
    "        table.columns=new_columns\n",
    "        \n",
    "        \n",
    "    if type(type_table)==tuple:\n",
    "        first_part_type=type_table[0]\n",
    "        if first_part_type==\"equipment\":\n",
    "            for_rename_cols={(\"наименован\",\"марк\"):\"resource_name\",\n",
    "                       (\"п/п\",):\"resource_id\",\n",
    "                       (\"примеч\",):'comments'\n",
    "                      }\n",
    "        elif first_part_type==\"human\":\n",
    "            for_rename_cols={(\"должност\",):\"resource_name\",\n",
    "                       (\"п/п\",):\"resource_id\",\n",
    "                       (\"примеч\",):'comments'\n",
    "                      }\n",
    "        else:\n",
    "            pass\n",
    "#             print(f\"Тип таблицы не определен для {table}\")\n",
    "    \n",
    "    if (type_table==\"work\")|(type(type_table)==tuple):\n",
    "        #Переименовываю все колонки к виду нужному для сохранения работ\n",
    "        for col in table.columns:\n",
    "            #Ищу и удаляю месяц\n",
    "            col_only_text=re.sub(\"[^А-я]+\",\"\",str(col))\n",
    "            if (col_only_text in M)|(col_only_text.capitalize() in M):\n",
    "                table.rename({col:re.sub(\"[^0-9.]+\",\"\",str(col))},axis=1,inplace=True)\n",
    "            \n",
    "            for words in for_rename_cols:\n",
    "                if all([w in str(col).lower() for w in words]):\n",
    "                    table.rename({col:for_rename_cols[words]},axis=1,inplace=True)\n",
    "            \n",
    "#     print(f\"Новые названия колонок {table.columns.to_list()}\")\n",
    "    \n",
    "def val_to_float(val):\n",
    "    new_val=re.sub(r\"[^0-9.]+\",\"\",str(val).replace(\",\",\".\").strip(\".\"))\n",
    "    try:\n",
    "        return round(float(new_val),3)\n",
    "    except:\n",
    "        return val\n",
    "\n",
    "def to_new_format(date):\n",
    "    data_pattern=r\"[0-9]{4}-[0-9]{2}-[0-9]{2}\"\n",
    "    if re.search(data_pattern,str(date))!=None:\n",
    "        data=re.findall(data_pattern,str(date))[0]\n",
    "        return f\"{data.split('-')[2]}.{data.split('-')[1]}.{data.split('-')[0]}\"\n",
    "    \n",
    "    if type(date)==type(datetime(2000, 1, 1)):\n",
    "        append_zero:lambda val: \"0\"+str(val) if len(str(val))==1 else str(val)\n",
    "        return f\"{append_zero(date.day)}.{append_zero(date.month)}.{date.year}\"            \n",
    "    return date\n",
    "\n",
    "def date_preproc(val_date,book):\n",
    "    try:\n",
    "        return to_new_format(xldate_as_datetime(val_date,book.datemode))\n",
    "    except:\n",
    "        first_var_date=val_date\n",
    "        \n",
    "        val_date=re.sub(r\"[^0-9.]+\",\"\",str(val_date)).strip(\".\")\n",
    "        try:\n",
    "            return to_new_format(xldate_as_datetime(val_date,book.datemode))\n",
    "        except:\n",
    "            \n",
    "            #Работает для xlsx файлов (заплатка, может упасть)\n",
    "            if val_date[:8].isdigit():\n",
    "                try:\n",
    "                    return to_new_format(str(pd.to_datetime(val_date)))\n",
    "                except:\n",
    "                    pass \n",
    "            \n",
    "            \n",
    "            parts_date=val_date.split(\".\")\n",
    "            if len(parts_date)==3:\n",
    "                if len(parts_date[0])==4: #Предполагаю что год первый в дате\n",
    "                    try:\n",
    "                        return to_new_format(datetime(int(parts_date[2]), int(date_parts[1]), int(date_parts[0])))\n",
    "                    except:\n",
    "                        pass\n",
    "                elif len(parts_date[0])==2: #Предполагаю что день первый в дате\n",
    "                    try:\n",
    "                        return to_new_format(datetime(int(parts_date[0]), int(date_parts[1]), int(date_parts[2])))\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            return to_new_format(first_var_date)\n",
    "\n",
    "# #Проверяем значение на наличие даты, если 14 цифр - считаем что это дата (8 дата + 6 время)\n",
    "#     '20170101000000', '2017-01-02 00:00:00'\n",
    "def is_date(val):\n",
    "    return len(re.sub('[^0-9]','',val))==14\n",
    "\n",
    "def date_prepros(date):\n",
    "    if len(date)==len('2017-01-01 00:00:00'):\n",
    "        return date\n",
    "    else:\n",
    "        numerical_date=re.sub('[^0-9]','',str(date))\n",
    "        return f\"{numerical_date[:4]}-{numerical_date[4:6]}-{numerical_date[6:8]} 00:00:00\" #! Только для ггггммдд\n",
    "\n",
    "#Старый вариант\n",
    "def day_prepros(day):\n",
    "    day=re.sub(r\"[^\\w.]\",\"\",str(day).replace(\".0\",\"\"))\n",
    "#     print(\"day first\",day)\n",
    "    #Убираем месяц\n",
    "    day=re.split(r'[ .,/\\-_]+', day)[0]\n",
    "    \n",
    "#     try:\n",
    "#         day=str(pd.to_datetime(str(day)).day)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "    \n",
    "    return day\n",
    "\n",
    "\n",
    "    \n",
    "def get_first_not_None(series):\n",
    "    vals=list(series)\n",
    "    not_None=lambda val:val not in [None,\"\"]\n",
    "    if any(map(not_None,vals)):\n",
    "        return [v for v in vals if not_None(v)][0]\n",
    "    else:\n",
    "        return \"\"\n",
    "#Органичения - если в индексе буквы индексом считатся не будет\n",
    "def is_numerical(val):\n",
    "    return (re.search(r\"^[0-9]+.[0-9]+\",str(val).strip(\".\"))!=None)|(str(val).isdigit())\n",
    "\n",
    "def calculating_mounth_plan_fact(progress): \n",
    "    calculated={\"plan\":[],\"fact\":[]}\n",
    "    for day_values in progress:\n",
    "        for day,values in day_values.items():\n",
    "            for plan_or_fact,val in values.items():\n",
    "                if is_numerical(val):\n",
    "                    calculated[plan_or_fact]=calculated[plan_or_fact]+[val_to_float(val)]\n",
    "    return sum(calculated['plan']),sum(calculated['fact'])\n",
    "\n",
    "#Достаем первое значение если переменная список, если нет - возвращаем переменную без изменений\n",
    "def get_first_val(val):\n",
    "    if type(val)==list:\n",
    "        if len(val)>0:\n",
    "            return val[0]\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "def get_first_not_None_val(val):\n",
    "    if type(val)==list:\n",
    "        float_is_not_none=lambda val:True if type(val)!=float else not np.isnan(val) #Функция для проверки float на none\n",
    "        val_not_None=[v for v in val if is_not_None(v)&float_is_not_none(v)]\n",
    "        if len(val_not_None)>0:\n",
    "            return val_not_None[0]\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "def preproc_if_series(val,type_val=None):\n",
    "    if type(val)!=type(pd.Series()):\n",
    "        return val\n",
    "    else:\n",
    "        val_list=list(val)\n",
    "\n",
    "        if (len(val_list)==1)|(type_val!=\"progress\"): #Только для progress допускается несколько значений \n",
    "            return str(val_list[0])\n",
    "        #Обрабатываем если скрипт пытается передать несколько значений в прогресс\n",
    "        elif (len(val_list)>1)&(type_val==\"progress\"):\n",
    "            not_None_vals=[v for v in val_list if (v!=None)&(v!=str(None))&(str(v)!=\"nan\")]\n",
    "            if len(not_None_vals)==1:\n",
    "                return str(not_None_vals[0])\n",
    "            elif len(not_None_vals)==0:\n",
    "                return None\n",
    "            else:\n",
    "                return not_None_vals\n",
    "        else:\n",
    "            return val_list\n",
    "\n",
    "#Тут построено на row[ind][0], возможно для xlsx это не работает\n",
    "def append_dict_from_rows_work(row,file_sheet_json):\n",
    "    work={\n",
    "        'work title': None, #+\n",
    "        'work id': None, #+\n",
    "        'upper works': [],#+\n",
    "        'measurements': None, #+\n",
    "        'amount': None, #+\n",
    "        'work_data': {\n",
    "        'start_date': {'plan': None, \n",
    "                       'estimate': None,\n",
    "                       'fact': None},#+\n",
    "            \n",
    "        'stop_date': {'plan': None,\n",
    "        'estimate': None,\n",
    "        'fact': None}, #'date in format dd.mm.yy' #+\n",
    "        'complite_state_perc': {'plan': None, 'fact': None}, #'in %' #+\n",
    "        'complite_state_value': {'plan': None, 'fact': None}, #+\n",
    "        'current_remain_perc': None, #'in %' #+\n",
    "        'current_remain_value': None, #'in %' #-\n",
    "        'whole_remain_perc': None,#'in %' #- общий % выполнения -1 +\n",
    "        'whole_remain_value': None,#+\n",
    "        'mounth_complite_value': {'plan': None, 'fact': None}, #+\n",
    "        'mounth_complite_perc': {'plan': None, 'fact': None}, #+'in %'\n",
    "        'progress': [], #array {'day_id': {'plan': 'value', 'fact': 'value'}\n",
    "        'comments': 'comment text' #+\n",
    "        }\n",
    "    }\n",
    "          \n",
    "    words=[\"plan\",\"estimate\",\"fact\"]\n",
    "    \n",
    "#     print(\"Добавляется в work строка\",row)\n",
    "    \n",
    "    #Тут упадет, если колонки не все строки\n",
    "    for ind in row.index:\n",
    "        if ind in list(work['work_data']):\n",
    "            if ind =='whole_remain_value': \n",
    "                row[ind]=val_to_float(preproc_if_series(get_first_val(row[ind][0])))\n",
    "                print(row[ind])\n",
    "                \n",
    "            elif ind=='comments':\n",
    "#                 print(\"comments_value\",row[ind])\n",
    "                row[ind]=str(get_first_not_None(row[ind])) #Предидущее row[0]\n",
    "            else:\n",
    "                pass\n",
    "            work[\"work_data\"][ind]=preproc_if_series(row[ind])\n",
    "        elif ind in list(work):\n",
    "            if ind=='work id':\n",
    "                row[ind][0]=ind_preprocess(row[ind][0])\n",
    "            work[ind]=str(row[ind][0]).strip(\" \")\n",
    "\n",
    "                    \n",
    "        elif any([w in ind for w in words]):\n",
    "            first_part,second_part=\"_\".join(ind.split(\"_\")[:-1]),ind.split(\"_\")[-1]\n",
    "            if first_part in [\"complite_state\",\"mounth_complite\"]:\n",
    "                work['work_data'][first_part+\"_value\"][second_part]=val_to_float(get_first_val(row[ind][0]))\n",
    "            elif any([w in ind for w in [\"start_date\",\"stop_date\"]]):\n",
    "                work['work_data'][first_part][second_part]=str(date_preproc_1(row[ind][0]))\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        \n",
    "            \n",
    "            \n",
    "        elif is_date(ind):\n",
    "            work['work_data']['progress']=work['work_data']['progress']+[{date_preproc_1(ind): {\n",
    "                'plan': get_first_not_None_val(row[ind][0]),\n",
    "                'fact': get_first_not_None_val(row[ind][1]) #get_first_not_None_val нужно для работы с дублирующимися датами\n",
    "            }}]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Расчитываем current remain percent and value\n",
    "    mounth_values=work['work_data'][\"mounth_complite_value\"]\n",
    "    if is_not_None(mounth_values[\"fact\"])&is_not_None(mounth_values[\"plan\"]):\n",
    "        try:\n",
    "            mounth_fact,mounth_plan=mounth_values[\"fact\"],mounth_values[\"plan\"]\n",
    "            if (mounth_fact<=mounth_plan)&(mounth_plan!=0):\n",
    "                work[\"work_data\"][\"current_remain_perc\"]=round((100-mounth_fact*100/mounth_plan),2)\n",
    "                work[\"work_data\"]['current_remain_value']=round(mounth_plan-mounth_fact,2)\n",
    "            else:\n",
    "                work[\"work_data\"][\"current_remain_perc\"],work[\"work_data\"]['current_remain_value']=0,0\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "\n",
    "#Убираем так как возможно правильно что план за месяц не совпадает с суммарным, может быть в этом есть идея  \n",
    "#     #calculating_mounth_plan_fact\n",
    "#     progress=work['work_data']['progress']\n",
    "#     print(progress,work['work_data']['progress'])\n",
    "#     work['work_data'][\"mounth_complite_value\"]['plan']=calculating_mounth_plan_fact(progress)[0]\n",
    "#     work['work_data'][\"mounth_complite_value\"]['fact']=calculating_mounth_plan_fact(progress)[1]\n",
    "            \n",
    "    if (work[\"amount\"] not in [None,0]):\n",
    "        #whole_remain to percent\n",
    "        if work[\"work_data\"][\"whole_remain_value\"]!=None:\n",
    "            try:\n",
    "                whole_remain_=work[\"work_data\"][\"whole_remain_value\"]\n",
    "                amount_=work[\"amount\"]\n",
    "                work[\"work_data\"][\"whole_remain_perc\"]=round((val_to_float(whole_remain_)*100)/val_to_float(amount_),2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "        #mounth_complite to percent\n",
    "        for first_part in ['complite_state',\"mounth_complite\"]:\n",
    "            for second_part in [\"plan\",\"fact\"]:\n",
    "                if work[\"work_data\"][first_part+\"_value\"][second_part]!=None:\n",
    "                    try:\n",
    "                        val1=work[\"work_data\"][first_part+\"_value\"][second_part]\n",
    "                        val2=work[\"amount\"]\n",
    "\n",
    "                        work[\"work_data\"][first_part+\"_perc\"][second_part]=round((val1*100)/val_to_float(val2),2)\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    #Заплатка - Если mounth_complite_value plan==0 current_remain_perc должно быть равно None\n",
    "    if work[\"work_data\"]['mounth_complite_value']['plan']==0:\n",
    "        work[\"work_data\"]['current_remain_perc']=None\n",
    "    \n",
    "    #Название работ цифровые скрипт не сохраняет\n",
    "    if ((val_is_index(work['work id']))|(work['work title']!=None))&(not str(work['work title']).isdigit()): #&(not (work[\"amount\"] in [None,\"\"])\n",
    "        file_sheet_json['work']+=[work]\n",
    "#         print(\"Успешно добавлена\",work)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_resource_from_work_table(row,file_sheet_json):   \n",
    "    resource={\n",
    "        'resource_id': None, #'id' #\n",
    "        'resource_name': None,#'name' #\n",
    "        'type': None, #'human/equipment/nan' #\n",
    "        'progress': [], #            {'day_id': [{'plan': 'amount','fact': 'amount'}\n",
    "        'comments': None} #'comment text' #\n",
    "\n",
    "    progress_values=[]\n",
    "    for ind in row.index:\n",
    "        if ind=='comments':\n",
    "            row[ind]=str(get_first_not_None(row[ind])) \n",
    "        elif ind=='work title':\n",
    "            resource['resource_name']=row[ind][0] #Так как таблица - работа, resource_name=work title\n",
    "        elif ind=='work id':\n",
    "            resource['resource_id']=row[ind][0] #Так как таблица - работа, work id=resource_id\n",
    "        elif is_date(ind):\n",
    "            resource['progress']=resource['progress']+[{date_preproc_1(ind): {\n",
    "                'plan': get_first_not_None_val(row[ind][0]),\n",
    "                'fact': get_first_not_None_val(row[ind][1])\n",
    "            }}]\n",
    "            progress_values.append(str(preproc_if_series(row[ind],type_val=\"progress\")))\n",
    "        else:\n",
    "            pass\n",
    "     \n",
    "    #Сохраняем если заполнено resource_name или любое значение прогресса непустое и есть индекс\n",
    "    if str(resource[\"resource_name\"]).replace(\".\",\"\",1).isdigit()==False: #Имя ресурса не может быть числовым\n",
    "        if ((str(resource[\"resource_name\"]).strip()!='')&(resource[\"resource_name\"]!=None))|(\n",
    "            any(list(map(lambda v:v not in [None,\"\",str(None),\"nan\",[\"\",\"\"],[None,None]],progress_values)))&(val_is_index(resource[\"resource_id\"]))):\n",
    "            file_sheet_json['resource']+=[resource]      \n",
    "    \n",
    "\n",
    "\n",
    "def append_dict_from_rows_recourses(row,file_sheet_json,table_have_plan_fact,type_resource):\n",
    "    resource={\n",
    "        'resource_id': None, #'id' #\n",
    "        'resource_name': None,#'name' #\n",
    "        'type': type_resource, #'human/equipment/nan' #\n",
    "        'progress': [], #            {'day_id': [{'plan': 'amount','fact': 'amount'}\n",
    "        'comments': None} #'comment text' #\n",
    "    \n",
    "\n",
    "    \n",
    "    progress_values=[]#Найденные значения погресса\n",
    "    for ind in row.index:\n",
    "        if ind in list(resource):\n",
    "            resource[ind]=get_first_val(preproc_if_series(row[ind]))\n",
    "        \n",
    "        elif is_date(ind):\n",
    "            if not table_have_plan_fact:\n",
    "                resource['progress']=resource['progress']+[{date_preproc_1(ind):preproc_if_series(row[ind],type_val=\"progress\")}]\n",
    "                progress_values.append(str(preproc_if_series(ind,type_val=\"progress\")))\n",
    "            else:\n",
    "                resource['progress']=resource['progress']+[{date_preproc_1(ind): {'plan': get_first_not_None_val(row[ind][0]),\n",
    "                                                                                  'fact': get_first_not_None_val(row[ind][1])}}]\n",
    "\n",
    "        elif (day_prepros(ind) in list(map(str,list(range(32))))):\n",
    "            if not table_have_plan_fact:\n",
    "                resource['progress']=resource['progress']+[{day_prepros(ind):preproc_if_series(row[ind],type_val=\"progress\")}]\n",
    "                progress_values.append(str(preproc_if_series(row[ind],type_val=\"progress\")))\n",
    "            else:\n",
    "                resource['progress']=resource['progress']+[{ind: {'plan': get_first_not_None_val(row[ind][0]),\n",
    "                                                                  'fact': get_first_not_None_val(row[ind][1])}}] #get_first_val для работы с дублирующимися датами\n",
    "\n",
    "            \n",
    "        else:\n",
    "#             print(f\"Не удалось добавить в json информацию из {str(ind)}\")\n",
    "            pass\n",
    "    \n",
    " \n",
    "    #is c\n",
    "    #Сохраняем если заполнено resource_name или любое значение прогресса непустое и есть индекс\n",
    "    if str(resource[\"resource_name\"]).replace(\".\",\"\",1).isdigit()==False: #Имя ресурса не может быть числовым\n",
    "        if ((str(resource[\"resource_name\"]).strip()!='')&(resource[\"resource_name\"]!=None)):\n",
    "#         |(any(list(map(lambda v:v not in [None,\"\",str(None),\"nan\",[\"\",\"\"],[None,None]],progress_values)))&(val_is_index(resource[\"resource_id\"]))):\n",
    "            file_sheet_json['resource']+=[resource]              \n",
    "\n",
    "            \n",
    "        \n",
    "#Удаляю повторение названий колонок (одно и то же написано дважды)       \n",
    "def del_double_name_cols(col):\n",
    "    parts=col.strip().split(\" \")\n",
    "    print(parts)\n",
    "    if len(parts)==4:\n",
    "        if parts[:2]==parts[2:4]:\n",
    "            return \" \".join(parts[:2])\n",
    "    return col\n",
    "    \n",
    "def table_preprocessing(table,file_sheet_json,type_table):\n",
    "    print(f\"Обрабатывается таблица типа {type_table}\")\n",
    "    #переименовываем колонки, в зависимости от типа таблицы\n",
    "    print(\"table\",table)\n",
    "    rename_cols(table,type_table=type_table)\n",
    "    \n",
    "    if type_table==\"work\":\n",
    "        #cобираю высокоуровневые работы в одну колонку\n",
    "        table['upper works']=pd.Series(\n",
    "            zip(*[table[col] for col in table.columns if \"high work\" in col]),table.index).apply(lambda L:[\n",
    "            v for v in L if (v!=None)&(v!=\"\")])\n",
    "        \n",
    "        #схлопываем индексы (тут могут возникать проблемы)\n",
    "        table['for_groupby']=table.index.map(lambda ind:ind if ind%2==0 else ind-1)\n",
    "        #Если количество нечетное - что то пошло не так, обрезаем последнюю строкуц\n",
    "        if table.shape[0]%2!=0:\n",
    "            table=table[:-1]\n",
    "        \n",
    "        \n",
    "#         if type_table==\"work\":\n",
    "#             try:\n",
    "#                 column_days=[c for c in table.columns if \"дни\" in str(c).lower()][0]\n",
    "#                 #План должен стоять на четном месте, факт на нечетном. Удаляем по одной несоответстсвующие строки\n",
    "                \n",
    "#                 table=table[((table[column_days]==\"план\")&(table.index%2==0))|((table[column_days]==\"факт\")&(table.index%2==1))]\n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "        table=table.groupby(\"for_groupby\").agg(list)\n",
    "#         print('new_table',table)\n",
    "#         print('new_table_columns',table.columns.tolist())\n",
    "        \n",
    "        #Удаляю все дубликаты колонок, оставляю последние (актуально для файлов ДСМПК с повторяющимися колонками дней)\n",
    "        table.columns=[str(c).strip(\" \").replace(\".0\",\"\") for c in table.columns]\n",
    "        \n",
    "        #Удаляю дубликаты  \n",
    "        table.columns=[del_double_name_cols(col) for col in table.columns]\n",
    "        \n",
    "        print(\"Колонки финальные названия\",list(table.columns))\n",
    "#         table = table.loc[:,~table.columns.duplicated(keep=\"last\")] #Считаем что последние значения наиболее актуальные\n",
    "        \n",
    "#         # Заплатка - переименовываю 30 день в 31 если 30 дней 2\n",
    "#         cols=table.columns.to_list()\n",
    "#         if cols.count(\"30\")==2:\n",
    "#             try:\n",
    "#                 last_ind=cols.index(\"30\")+1\n",
    "#                 while cols[last_ind]!=\"30\":\n",
    "#                     last_ind+=1\n",
    "#                 cols[last_ind]=\"31\"  \n",
    "#                 table.columns=cols\n",
    "                \n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "        #добавляю все работы из table к file_sheet_json, и ресурсы по отдельному алгоритму\n",
    "        for i,row in table.iterrows():\n",
    "            print(row.values)\n",
    "            if \"resource\" in str(get_first_val(preproc_if_series(row['work id']))):\n",
    "                append_resource_from_work_table(row,file_sheet_json) #если resource в индексе - добавляем к ресурсам\n",
    "            else:\n",
    "                append_dict_from_rows_work(row,file_sheet_json) #если нет - к работам\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    elif type(type_table)==tuple: #Таблица ресурс\n",
    "        table_have_plan_fact=False\n",
    "        \n",
    "        cols_line=\" \".join(table.columns.tolist())\n",
    "        print(\"cols_line_1\",cols_line)\n",
    "        for c in table.columns:\n",
    "            print(c,set(table[c]))\n",
    "        #Проверяем есть ли столбец с план-факт в значениях\n",
    "        pal_fact_in_col=any([all([w in set(table[c]) for w in [\"факт\",\"план\"]]) for c in table.columns])\n",
    "        print(\"pal_fact_in_col\",pal_fact_in_col)\n",
    "        \n",
    "        #Группирую строки так как там есть план факт\n",
    "        if (re.search(r\"дни\",cols_line.lower())!=None)|(pal_fact_in_col): #Если в колонке есть столбик со словом дни - план факт там должен быть\n",
    "            table_have_plan_fact=True\n",
    "            \n",
    "            #схлопываем индексы (тут могут возникать проблемы)\n",
    "            table['for_groupby']=table.index.map(lambda ind:ind if ind%2==0 else ind-1)\n",
    "            \n",
    "            #Если количество нечетное - что то пошло не так, обрезаем последнюю строкуц\n",
    "            if table.shape[0]%2!=0:\n",
    "                table=table[:-1]\n",
    "            \n",
    "            table=table.groupby(\"for_groupby\").agg(list)\n",
    "            print(\"table_1\",table)\n",
    "            \n",
    "        \n",
    "        first_part_type=type_table[0]\n",
    "        \n",
    "        #Удаляю все дубликаты колонок, оставляю последние (актуально для файлов ДСМПК с повторяющимися колонками дней)\n",
    "        table.columns=[str(c).strip(\" \").replace(\".0\",\"\") for c in table.columns]\n",
    "#         table = table.loc[:,~table.columns.duplicated(keep=\"last\")] #Считаем что последние значения наиболее актуальные\n",
    "#         print('table_resources',table)\n",
    "#         print('table_resources_columns',table.columns.tolist())\n",
    "        \n",
    "        #Удаляю дубликаты  \n",
    "        table.columns=[del_double_name_cols(col) for col in table.columns]\n",
    "    \n",
    "#         Заплатка - переименовываю 30 день в 31 если 30 дней 2\n",
    "#         cols=table.columns.to_list()\n",
    "#         if cols.count(\"30\")==2:\n",
    "#             try:\n",
    "#                 last_ind=cols.index(\"30\")+1\n",
    "#                 while cols[last_ind]!=\"30\":\n",
    "#                     last_ind+=1\n",
    "#                 cols[last_ind]=\"31\"  \n",
    "#                 table.columns=cols\n",
    "                \n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "        [append_dict_from_rows_recourses(row,\n",
    "                                         file_sheet_json,\n",
    "                                         table_have_plan_fact,\n",
    "                                         type_resource=first_part_type) for i,row in table.iterrows()]\n",
    "        \n",
    "#Переименовываю колонку с план/факт\n",
    "def rename_plan_fact_col(table,cols):\n",
    "    for i in range(table.shape[1]):\n",
    "        col_i=table.columns.tolist()[i]\n",
    "        strip_all_val=lambda List:list(map(lambda v:str(v).strip(),List))\n",
    "        if all([w in strip_all_val(list(table[col_i])) for w in ['план','факт']]):\n",
    "            if len(cols)-1>=i:\n",
    "                cols[i]=\"Дни мес.\"\n",
    "            \n",
    "def table_to_json(file_sheet_json,\n",
    "                  sh,\n",
    "                  start_table_rx,\n",
    "                  end_table_rx,\n",
    "                  last_head_rx,\n",
    "                  type_file):\n",
    "    \n",
    "    #Creating df\n",
    "    cols=create_cols(sh,start_table_rx,last_head_rx,type_file)\n",
    "    print(f\"Извлеченные названия колонок, {cols}\")\n",
    "    \n",
    "    #Type table\n",
    "    type_table=check_type_table(cols)\n",
    "    \n",
    "    #Сreate new names cols for select rows with work\n",
    "    empy_table=pd.DataFrame(columns=cols)\n",
    "    rename_cols(empy_table,type_table=type_table)\n",
    "    new_name_cols=empy_table.columns.tolist()\n",
    "#     print(\"new_name_cols\",new_name_cols)\n",
    "    \n",
    "    vals=create_vals(sh,last_head_rx,end_table_rx,type_file,type_table,new_name_cols)\n",
    "    table=pd.DataFrame(data=vals) #!vals и cols не равны\n",
    "    \n",
    "    #Нахожу и переименовываю колонку с план/факт в cols\n",
    "    rename_plan_fact_col(table,cols)\n",
    "    print(\"cols_1\",cols)\n",
    "        \n",
    "            \n",
    "            \n",
    "#     print(table)\n",
    "    \n",
    "    if table.shape[0]==0:\n",
    "        print(f\"Получена пустая таблица {start_table_rx,end_table_rx,last_head_rx}\")\n",
    "    else:\n",
    "        table.columns=cols+[f\"high work level {i}\" for i in range(table.shape[1]-len(cols))]\n",
    "        new_cols=table.columns.to_list()\n",
    "        print(\"Смотрю значения 1\")\n",
    "        for c in table.columns:\n",
    "            print(c,set(table[c]))\n",
    "        table_preprocessing(table,file_sheet_json,type_table=check_type_table(new_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем файл уже обрабатывался или нет\n",
    "def is_file_already_preprocessed(file,sh_name):\n",
    "    files=pd.read_csv(\"Successfully preprocessed files.xlsx\",index_col=\"index\")\n",
    "    return files[(files[\"files\"]==file)&(files[\"sh_name\"]==sh_name)].shape[0]!=0\n",
    "\n",
    "\n",
    "#Добавляем уже обработанный файл в табличку\n",
    "def append_preprocessed_file(file,sh_name):\n",
    "    files=pd.read_csv(\"Successfully preprocessed files.xlsx\",index_col=\"index\")\n",
    "    if files.shape[0]==0:\n",
    "        files.loc[0]=file\n",
    "    else:\n",
    "        last_index=files.index.to_list()[-1]\n",
    "        files.loc[int(last_index)+1]=[file,sh_name]\n",
    "    files.to_csv(\"Successfully preprocessed files.xlsx\",index_label=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Снятие защиты с защищенного файла xsl\n",
    "def decrypt_xlsx_files(file,full_path_parsing):\n",
    "    input_path=full_path_parsing\n",
    "    output_path=os.path.join(\"Data for parsing\",\"decrypted files\")\n",
    "    \n",
    "    #Создаем директорию для сохранения расшифрованного файла если ее еще нет\n",
    "    isExist = os.path.exists(output_path)\n",
    "    if not isExist:\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    \n",
    "    data = msoffcrypto.OfficeFile(open(os.path.join(input_path, file), 'rb'))\n",
    "    data.load_key(password='VelvetSweatshop')  # 默认密码为'VelvetSweatshop'\n",
    "    data.decrypt(open(os.path.join(output_path, file), 'wb'))  # 输出无密码保护\n",
    "    print('finished' + file)\n",
    "\n",
    "    #Открываем книгу\n",
    "    _book = xlrd.open_workbook(os.path.join(output_path, file))\n",
    "    return _book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ищем месяц который будем парсить\n",
    "def get_month(file_name):\n",
    "    #Ищем текстовый месяц в названии файла\n",
    "    for m in M:\n",
    "        if m.lower() in file_name.lower():\n",
    "            return m.lower()\n",
    "    \n",
    "    numbs=re.sub(\"[^0-9 ,-_]\",\"\",file_name)\n",
    "    numbs=re.sub(\"[ ,-/_]\",\" \",numbs)\n",
    "    \n",
    "    numbs=re.sub(\" +\",\" \",numbs)\n",
    "    \n",
    "    parts=numbs.strip().split(\" \")\n",
    "\n",
    "    #месяц всегда второй\n",
    "    try:\n",
    "        #Ищем год\n",
    "        if (len(parts[0])==4)|(len(parts[-1])==4): #Предполагаем что минимум две части есть, и год сбоку\n",
    "            if \"20\" in str(parts[0]):\n",
    "                year=0\n",
    "                month=1\n",
    "            elif \"20\" in str(parts[-1]):\n",
    "                year=-1\n",
    "                month=-2\n",
    "            else:\n",
    "                return str(M_[int(parts[1])]).lower()\n",
    "            return str(M_[int(parts[month])]).lower()\n",
    "        elif (len(parts[0])==2)|(len(parts[-1])==2):\n",
    "            num_0=int(parts[0])\n",
    "            num_minus_1=int(parts[-1])\n",
    "            if num_minus_1 in range(15,18): #Обычно год вконце\n",
    "                year=-1\n",
    "                month=-2\n",
    "                \n",
    "            elif num_0 in range(15,18):\n",
    "                year=0\n",
    "                month=1\n",
    "            else:\n",
    "                return str(M_[int(parts[1])]).lower()\n",
    "            return str(M_[int(parts[month])]).lower()\n",
    "    except:\n",
    "        try:\n",
    "            return str(M_[int(parts[1])]).lower()\n",
    "        except:\n",
    "            print(f\"Не получилось найти месяц в названии {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1_Мессояха_MСГ_30.01.2015.json\n",
    "#Создаем имя файла\n",
    "def get_index_for_filename(file_name,full_path_save):\n",
    "    indexes_in_folder=[int(file_name.split(\"_\")[0]) for file_name in os.listdir(full_path_save)]\n",
    "    if len(indexes_in_folder)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(indexes_in_folder)+1\n",
    "\n",
    "def create_file_name(file_name,path_parsing,full_path_save):\n",
    "    year=path_parsing.split(r\"/\")[0] #Определяем год по имени папки с файлом\n",
    "    day,month=\"xx\",\"xx\"\n",
    "    second_part_year=year[2:] #Год всегда 4 цифры\n",
    "    \n",
    "    numbs=re.sub(\"[^0-9 .,/\\-_]\",\"\",file_name)\n",
    "    numbs=re.sub(\"[ .,/\\-_]\",\" \",numbs)\n",
    "    numbs=re.sub(\" +\",\" \",numbs).strip()\n",
    "    \n",
    "    parts=numbs.strip().split(\" \")\n",
    "    if len(parts)>3: #2 раза указан год и возможно есть какой то мусор, находим эти 2 раза и обрезаем лишнюю часть\n",
    "        new_parts=[]\n",
    "        for p in parts:\n",
    "            if second_part_year in p:\n",
    "                if parts.index(p) in [0,2]: #Первые 3 числа - то что нужно\n",
    "                    parts=parts[:3]\n",
    "                    break\n",
    "                if parts.index(p)==1: #считаем что первое число - год\n",
    "                    parts=parts[1:4]\n",
    "                    break\n",
    "                if parts.index(p)>2:\n",
    "                    parts=parts[parts.index(p)-2,parts.index(p)+1]\n",
    "                    break\n",
    "        \n",
    "    try:\n",
    "        #В какой то части должен быть год, либо в первой либо в последней\n",
    "        if (second_part_year in parts[-1])&(second_part_year not in parts[0]):\n",
    "            #Если в последней значит день-месяц в первых двух\n",
    "            if len(parts)==3:\n",
    "                month=parts[1]\n",
    "                day=parts[0]\n",
    "            elif len(parts)==2:\n",
    "                #предполагаем что записан только месяц\n",
    "                month=parts[0]\n",
    "                if len(month)>2: #cчитаем что день и месяц слиплись\n",
    "                    day=month[:-2] #День первый если год последний\n",
    "                    month=month[-2:]\n",
    "                    \n",
    "            else:\n",
    "                print(\"Месяц не определяется\")\n",
    "                \n",
    "        elif (second_part_year in parts[0])&(second_part_year not in parts[-1]): #год в первой части, нет в последней\n",
    "            #Если в первой значит месяц-день две последние\n",
    "            if len(parts)==3:\n",
    "                month=parts[1]\n",
    "                day=parts[-1]\n",
    "                \n",
    "            elif len(parts)==2:\n",
    "                #предполагаем что записан только месяц\n",
    "                month=parts[1]\n",
    "                if len(month)>2: #cчитаем что день и месяц слиплись\n",
    "                    day=month[2:]\n",
    "                    month=month[:2]\n",
    "                    \n",
    "            else:\n",
    "                pass\n",
    "#                 print(f\"Месяц не определяется для {file_name}\")\n",
    "        elif (second_part_year in parts[0])&(second_part_year in parts[-1]): #День и год совпадают (год и месяц не могут) для годов 15-17\n",
    "            day=second_part_year\n",
    "            if len(parts)==3:\n",
    "                month=parts[1]\n",
    "    except:\n",
    "        pass\n",
    "#         print(f\"Дата не определяется для {file_name}\")\n",
    "    \n",
    "    #Меняю местами месяц и день если месяц больше 12 а день меньше\n",
    "    try:\n",
    "        if (int(month)>12)&(int(day)<=12):\n",
    "            past_day_month=(day,month)\n",
    "            day,month=past_day_month[1],past_day_month[0]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "            \n",
    "    #Создаю имя файла\n",
    "    day_month_preproc=lambda v:\"0\"+str(v) if len(str(v))==1 else str(v)\n",
    "    \n",
    "    date=f\"{day_month_preproc(day)}.{day_month_preproc(month)}.{year}\"\n",
    "    index=get_index_for_filename(file_name,full_path_save)\n",
    "         \n",
    "    new_file_name=f\"{index}_ТИП_{date}\"\n",
    "    for ob in [\"ВЛ\",\"ГТЭС\"]:\n",
    "        if ob in file_name:\n",
    "            new_file_name+=f\"_{ob}\"\n",
    "    return new_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba798393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция поиска имени объекта в файле\n",
    "def get_object(book,sheets,month_for_parsing,type_file):\n",
    "    #Ставим нужный sh_name на первое место\n",
    "    for sh_name in sheets:\n",
    "        if (re.search(month_for_parsing,sh_name.lower())!=None)&(re.search(\"правила\",str(sh_name).lower())==None)&(re.search(\"обр\",str(sh_name).lower())==None): \n",
    "            sheets=[sh_name]+sheets\n",
    "            break\n",
    "    \n",
    "    #Ищем object_,object_2 - первый объектв в шапке, второй в таблице работ\n",
    "    object_=None\n",
    "    object_2=None\n",
    "            \n",
    "    #Ищем имя объекта последовательно во всех листах, начиная с нужного \n",
    "    for sh_name in sheets:\n",
    "        if re.search(\"правила\",str(sh_name).lower())==None: #Не интересуют листы правила заполнения/составления МСГ\n",
    "            \n",
    "            #Файл для сохранения ресурсов\n",
    "            if type_file==\"xls\":\n",
    "                sh = book.sheet_by_name(sh_name)\n",
    "            if type_file==\"xlsx\":\n",
    "                sh = book[sh_name]\n",
    "\n",
    "            if type_file==\"xls\":\n",
    "                num_rows = sh.nrows\n",
    "            if type_file==\"xlsx\":\n",
    "                num_rows = sh.max_row\n",
    "            \n",
    "            \n",
    "                \n",
    "            for rx in range(num_rows):\n",
    "                \n",
    "                if type_file==\"xls\":\n",
    "                    row=sh.row(rx)\n",
    "\n",
    "                if type_file==\"xlsx\":\n",
    "                    rx+=1 #Начинается с единицы\n",
    "                    row=sh[rx]\n",
    "                row_value=[str(cell.value) for cell in row if str(cell.value) not in [None,\"\",\"nan\",str(None)]]\n",
    "                row_line=\" \".join(row_value)\n",
    "                row_value_not_None=[v for v in row_value if is_not_None(v)]\n",
    "                \n",
    "                \n",
    "                if (\"по объекту\" in row_line):\n",
    "                    object_=row_line.split(\"по объекту\")[1].strip(\":\").strip(\" \")\n",
    "                \n",
    "                try:\n",
    "                    if list(map(lambda val:str(int(val)),row_value_not_None[:4]))==['1','2','3','4']:\n",
    "                        new_row=sh[rx+1]\n",
    "                        new_row_value=[str(cell.value) for cell in new_row if str(cell.value) not in [None,\"\",\"nan\",str(None)]]\n",
    "                        new_row_value_not_None=[v for v in new_row_value if is_not_None(v)]\n",
    "                        if (len(new_row_value_not_None)==1):\n",
    "                            object_2=new_row_value_not_None[0]\n",
    "                    \n",
    "                            if is_not_None(object_)&is_not_None(object_2):\n",
    "                                return object_,object_2 \n",
    "                except:\n",
    "                    pass\n",
    "            if is_not_None(object_): #object_2 ищем только на листе с object_\n",
    "                return object_,object_2\n",
    "    return object_,object_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d9cf5",
   "metadata": {},
   "source": [
    "#### Задаем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30babe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ячейка парсит все файлы в folder\n",
    "root_path_parsing=\"Data for parsing/\"\n",
    "path_parsing=\"2017/2017_03\"\n",
    "full_path_parsing=os.path.join(root_path_parsing,path_parsing)\n",
    "\n",
    "root_path_save=\"Preprocessed files\"\n",
    "full_path_save=os.path.join(root_path_save,path_parsing)\n",
    "# full_path_save=os.path.join(root_path_save,\"2015 preprocessed\")\n",
    "\n",
    "#Создаем директорию для сохранения файлов\n",
    "isExist = os.path.exists(full_path_save)\n",
    "if not isExist:\n",
    "    os.makedirs(full_path_save)\n",
    "\n",
    "# # #Пробую переименовать все файлы в директории с xlsx к xls\n",
    "# transform_all_xlsx_files_to_xls(full_path_parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    For the given path, get the List of all files in the directory tree \n",
    "'''\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8e488",
   "metadata": {},
   "source": [
    "row_values_not_none ['Подготовительные работы', 'план']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58ae71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "not_preprocessed_file=[]\n",
    "\n",
    "# #Сам процесс парсинга\n",
    "# for folder in tqdm_notebook(os.listdir(full_path_parsing)):\n",
    "#генерируем все возможные пути папок\n",
    "all_paths=getListOfFiles(full_path_parsing)\n",
    "\n",
    "for full_path in tqdm_notebook(all_paths):\n",
    "    file=full_path.split(\"\\\\\")[-1]\n",
    "    last_folder=\"\\\\\".join(full_path.split(\"\\\\\")[:-1]) #Нужна финальная директория, без файла\n",
    "\n",
    "    list_for_file_saved=False #маркер успешного сохранения минимум 1 листа\n",
    "\n",
    "    filename, file_extension = os.path.splitext(file)\n",
    "    if (file_extension not in [\".db\",\".doc\",\".docx\"])&(\"thumbs\" not in filename.lower()):\n",
    "\n",
    "        print(f\"Началась обработка файла {file}\")\n",
    "#             full_path=os.path.join(last_folder,file)\n",
    "        month_for_parsing=get_month(filename)\n",
    "\n",
    "        #Часть файлов в xlsx, их сначала переводим в xls, далее \n",
    "        try:\n",
    "            book = xlrd.open_workbook(full_path)\n",
    "            type_file=\"xls\"\n",
    "        except Exception as e:\n",
    "            if str(e) == \"Workbook is encrypted\":\n",
    "                book = decrypt_xlsx_files(file,last_folder) #Расшифровка зашифрованного файла\n",
    "                type_file=\"xls\"\n",
    "            else:\n",
    "                try:\n",
    "                    book = openpyxl.load_workbook(full_path,data_only=True) #! data_only сохраняет последнее значение ,\n",
    "                    # добавил\n",
    "                    \n",
    "                    type_file=\"xlsx\"\n",
    "                except:\n",
    "                        rename_path=full_path.replace(file_extension,\".xlsx\")\n",
    "                        os.rename(full_path,rename_path)\n",
    "\n",
    "                        book = openpyxl.load_workbook(rename_path,data_only=True) #! data_only сохраняет последнее значение\n",
    "                        type_file=\"xlsx\"\n",
    "\n",
    "        #Задаем книгу для расшифровки дат\n",
    "        def date_preproc_1(date_val,book=book):\n",
    "            return date_preproc(date_val,book)\n",
    "\n",
    "        if type_file==\"xls\":\n",
    "            sheets=book.sheet_names()\n",
    "        if type_file==\"xlsx\":\n",
    "            sheets=book.sheetnames\n",
    "\n",
    "        for sh_name in sheets:\n",
    "            \n",
    "            #### ВЫГРУЖАЕМ ТОЛЬКО ДРУГИЕ ЛИСТЫ ДКС ###\n",
    "            \n",
    "            if (re.search(month_for_parsing,sh_name.lower())==None)&(\"ДКС\" in str(filename)): #not is_file_already_preprocessed(full_path,sh_name)\n",
    "                if re.search(\"правила\",str(sh_name).lower())==None: #Не интересуют листы правила заполнения/составления МСГ\n",
    "                    #Файл для сохранения ресурсов\n",
    "                    file_sheet_json={\n",
    "                                    'file_name': file.strip(\".xls\").strip(\".xlsx\")+\"_\"+sh_name,\n",
    "                                    'object':get_object(book,sheets,month_for_parsing,type_file)[0],\n",
    "                                    'object_1':get_object(book,sheets,month_for_parsing,type_file)[1],\n",
    "                                    'work': [],\n",
    "                                    'resource': [],\n",
    "\n",
    "                                }\n",
    "\n",
    "                    print(f\"Началась обработка листа {sh_name}\")\n",
    "\n",
    "                    if type_file==\"xls\":\n",
    "                        sh = book.sheet_by_name(sh_name)\n",
    "                    if type_file==\"xlsx\":\n",
    "                        sh = book[sh_name]\n",
    "                    print(\"Тип файла определен как\",type_file)\n",
    "                    #ОБРАБОТКА ЛИСТА\n",
    "                    #Ищем нужные строки, ограничивающие таблицу - первая и последняя строка таблицы, последняя строка заголовков\n",
    "                    start_table_rx=None\n",
    "                    end_table_rx=None\n",
    "                    last_head_rx=None\n",
    "                    start_next_table_rx=None\n",
    "\n",
    "\n",
    "                    if type_file==\"xls\":\n",
    "                        num_rows = sh.nrows\n",
    "                    if type_file==\"xlsx\":\n",
    "                        num_rows = sh.max_row\n",
    "    #                 print(\"num_rows\",num_rows)\n",
    "\n",
    "                    #Для xls перебираем от 0 до  num_rows-1, который последний, т.е. перебираем все\n",
    "                    #Для xlsx перебираем от 1 до num_rows , который последний, т.е. перебираем все\n",
    "                    print(\"num_rows\",num_rows)\n",
    "                    for rx in range(num_rows):\n",
    "#                         print(rx)\n",
    "                        if type_file==\"xls\":\n",
    "                            row=sh.row(rx)\n",
    "\n",
    "                        if type_file==\"xlsx\":\n",
    "                            rx+=1 #Начинается с единицы\n",
    "                            row=sh[rx]\n",
    "\n",
    "\n",
    "\n",
    "                        print(\"rx\",rx)\n",
    "                        row_values=[\n",
    "                            re.sub(\"\\n\",\" \",str(cell.value)).strip() for cell in row if (cell.value!=\"\")&(cell.value!=None)]\n",
    "    #                     print(\"finding borders table\",row_values)\n",
    "                        row_line=\"|\".join(row_values)\n",
    "                        print(\"row_line\",row_line)\n",
    "\n",
    "\n",
    "                        if len(row_values)!=0: #Пустые строки не интересны для поиска границ таблиц\n",
    "\n",
    "                            first_val=row_values[0]\n",
    "\n",
    "                            #Проверка наличия маркера старта таблицы\n",
    "                            start_table_markers=[\"п/п\",\"наименование должностей, профессий\",\"наименование и марка техники\"] \n",
    "                            marker_in_line=lambda line: any([(m in str(line).lower()) for m in start_table_markers])  \n",
    "\n",
    "    #                         print(rx,num_rows-1,type(rx))\n",
    "\n",
    "                            #Ищем границы таблицы\n",
    "                            if (any([marker_in_line(val) for val in row_values]))&(start_table_rx==None):\n",
    "                                start_table_rx=rx\n",
    "    #                             print(\"start_table_rx определено start_table_marker\")\n",
    "                            elif (any([marker_in_line(val) for val in row_values]))&(start_table_rx!=None):\n",
    "                                end_table_rx=rx-1\n",
    "                                start_next_table_rx=rx\n",
    "    #                             print(\"end_table_rx определено start_table_marker\")\n",
    "\n",
    "\n",
    "                            elif (rx==num_rows-1)|(re.search(\"Процент выполнения МСГ\",row_line)!=None):\n",
    "                                end_table_rx=rx\n",
    "    #                             print(\"end_table_rx определено num_rows-1\")\n",
    "                            elif (re.search(\"ИТОГО\",row_line)!=None):\n",
    "                                end_table_rx=rx+1\n",
    "                \n",
    "                            elif (sum([1 for v in list(range(1,29)) if str(int(v)) in row_line])>=26)&(last_head_rx==None): #должно быть минимум 25 дат\n",
    "                                last_head_rx=rx #!\n",
    "    #                             print(\"last_head_rx определено\")\n",
    "\n",
    "                            else:\n",
    "                                pass\n",
    "                        if rx==num_rows-1:\n",
    "                            end_table_rx=rx\n",
    "                            print(\"end_table_rx определено num_rows-1\")\n",
    "\n",
    "                        if all(v is not None for v in [start_table_rx,end_table_rx,last_head_rx]):\n",
    "                            print(start_table_rx,end_table_rx,last_head_rx)\n",
    "    #                         try:\n",
    "                            table_to_json(file_sheet_json,\n",
    "                                          sh,\n",
    "                                          start_table_rx,\n",
    "                                          end_table_rx,\n",
    "                                          last_head_rx,\n",
    "                                          type_file\n",
    "                                         )\n",
    "\n",
    "    #                         except:\n",
    "    #                             print(\n",
    "    #                 f\"Не удалось сохранить таблицу в json, {file} {sh_name} {(start_table_rx,end_table_rx,last_head_rx)}\"\n",
    "    #                             )\n",
    "    #                             #Показываю ошибку\n",
    "    #                             traceback.print_exc()\n",
    "\n",
    "                            #Обновляем индексы    \n",
    "                            start_table_rx=None\n",
    "                            end_table_rx=None\n",
    "                            last_head_rx=None\n",
    "\n",
    "                            if start_next_table_rx!=None:\n",
    "                                start_table_rx=start_next_table_rx\n",
    "                                start_next_table_rx=None\n",
    "\n",
    "                                print(\"Индексы обновлены\",start_table_rx,end_table_rx,last_head_rx)\n",
    "\n",
    "                        #Если в строке ПОДПИСИ СТОРОН - она финальная, дальше смотреть строки не нужно \n",
    "                        if re.search(\"ПОДПИСИ СТОРОН\",row_line)!=None: \n",
    "                            break\n",
    "\n",
    "    #                 print(start_table_rx,end_table_rx,last_head_rx)\n",
    "                    ###ЛИСТ ПРОЧИТАЛИ СОХРАНЯЕМ РЕЗУЛЬТАТ\n",
    "\n",
    "                    #Saving json\n",
    "                    with open(os.path.join(full_path_save,create_file_name(filename,\n",
    "                                                                           path_parsing,\n",
    "                                                                           full_path_save)+\".json\"),\n",
    "                              \"w\",\n",
    "                              encoding='utf8') as save_file:\n",
    "\n",
    "                        json.dump(file_sheet_json,save_file)\n",
    "                    list_for_file_saved=True\n",
    "    #                 #Save preprocessed file name\n",
    "    #                 append_preprocessed_file(full_path,sh_name)\n",
    "\n",
    "            else:\n",
    "                print(f\"Не обработан {full_path} {sh_name}\")\n",
    "        if not list_for_file_saved:\n",
    "            not_preprocessed_file.append(filename)\n",
    "\n",
    "not_preprocessed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba625b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file=\"0_ТИП_28.02.2017.json\"\n",
    "# path=os.path.join(full_path_save,file)\n",
    "# print(path)\n",
    "# with open(path,\"r\",encoding=\"utf-8\") as read_file:\n",
    "#     dat=json.load(read_file)\n",
    "# # type(dat['work'][0]['work_data']['progress'][23]['24.02.2017']['plan'])\n",
    "# dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612a2e2",
   "metadata": {},
   "source": [
    "Заметки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e3965",
   "metadata": {},
   "source": [
    "whole_remain_perc - что то странное"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
